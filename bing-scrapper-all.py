import os
import requests
from bs4 import BeautifulSoup
import json
import time
import random

# --- KONFIGURACJA ---
OUTPUT_DIR = "scan-candidates"
LIMIT = 20  # Liczba zdjÄ™Ä‡ na kategoriÄ™

# Agresywne zapytania nakierowane na wypeÅ‚nione dokumenty
CATEGORIES = {
    # --- FINANCIAL ---
    "pit11": "PIT-11 przykÅ‚ad wypeÅ‚nienia skan",
    "pit37": "PIT-37 wypeÅ‚niony formularz dane",
    "pit36": "PIT-36 uzupeÅ‚niony przykÅ‚ad",
    "pit36L": "PIT-36L wypeÅ‚niony skan",
    "pit28": "PIT-28 wypeÅ‚niona deklaracja",
    "pit38": "PIT-38 przykÅ‚ad uzupeÅ‚niony",
    "pit39": "PIT-39 przykÅ‚adowe dane",
    "pit5": "PIT-5 wypeÅ‚niony formularz skan",
    "pit8C": "PIT-8C wypeÅ‚niony dane",
    "vat7": "VAT-7 deklaracja wypeÅ‚niona przykÅ‚ad",
    "cit8": "CIT-8 uzupeÅ‚niony formularz",
    "pcc3": "PCC-3 wypeÅ‚niony przykÅ‚ad",
    "invoice": "faktura vat wypeÅ‚niona dane skan",
    "proformaInvoice": "faktura proforma uzupeÅ‚niona dane",
    "receipt": "paragon fiskalny zdjÄ™cie realne",
    "utilityBill": "rachunek za prÄ…d uzupeÅ‚niony dane",
    "bankStatement": "wyciÄ…g bankowy realny przykÅ‚ad",
    "loanAgreement": "umowa poÅ¼yczki wypeÅ‚niona dane",
    "insurancePolicy": "polisa ubezpieczeniowa wypeÅ‚niona skan",

    # --- LEGAL ---
    "notarialDeed": "akt notarialny skan z danymi",
    "courtJudgment": "wyrok sÄ…du wypeÅ‚niony uzupeÅ‚niony",
    "powerOfAttorney": "peÅ‚nomocnictwo uzupeÅ‚nione dane",
    "employmentContract": "umowa o pracÄ™ wypeÅ‚niona dane",
    "mandateContract": "umowa zlecenie uzupeÅ‚niona przykÅ‚adowa",
    "taskContract": "umowa o dzieÅ‚o wypeÅ‚niona skan",
    "b2bContract": "umowa B2B wypeÅ‚niona dane",
    "nonCompeteAgreement": "zakaz konkurencji uzupeÅ‚niony przykÅ‚ad",
    "lawsuit": "pozew cywilny wypeÅ‚niony skan",

    # --- PERSONAL ---
    "idCard": "dowÃ³d osobisty specimen dane polska",
    "passport": "paszport polski specimen dane",
    "birthCertificate": "odpis aktu urodzenia wypeÅ‚niony",
    "marriageCertificate": "akt maÅ‚Å¼eÅ„stwa uzupeÅ‚niony dane",
    "deathCertificate": "akt zgonu wypeÅ‚niony przykÅ‚ad",
    "peselConfirmation": "potwierdzenie nadania PESEL wypeÅ‚nione",
    "drivingLicense": "prawo jazdy specimen polska",
    "schoolCertificate": "Å›wiadectwo szkolne wypeÅ‚nione dane",
    "universityDiploma": "dyplom ukoÅ„czenia studiÃ³w wypeÅ‚niony",
    "professionalCertificate": "certyfikat zawodowy uzupeÅ‚niony",
    "cv": "Å¼yciorys CV wypeÅ‚niony dane",

    # --- HEALTH ---
    "sickLeave": "zwolnienie lekarskie L4 wypeÅ‚nione skan",
    "prescription": "recepta lekarska wypisana dane",
    "medicalResults": "wyniki badaÅ„ laboratoryjnych dane pacjenta",
    "referral": "skierowanie do lekarza uzupeÅ‚nione",
    "medicalHistory": "karta pacjenta wypeÅ‚niona skan",
    "vaccinationCard": "karta szczepieÅ„ uzupeÅ‚niona",
    "sanitaryBooklet": "ksiÄ…Å¼eczka sanepidowska wypeÅ‚niona",

    # --- PROPERTY ---
    "propertyDeed": "akt wÅ‚asnoÅ›ci nieruchomoÅ›ci uzupeÅ‚niony",
    "landRegistry": "ksiÄ™ga wieczysta odpis przykÅ‚ad",
    "rentalAgreement": "umowa najmu mieszkania wypeÅ‚niona dane",
    "registrationCertificate": "dowÃ³d rejestracyjny pojazdu uzupeÅ‚niony",
    "vehicleHistory": "raport historii pojazdu dane",
    "landMap": "mapa geodezyjna skan",
    "technicalInspection": "zaÅ›wiadczenie o badaniu technicznym wypeÅ‚nione",

    # --- OTHER ---
    "documentScan": "skan dokumentu z tekstem i pieczÄ…tkÄ…",
    "application": "wniosek urzÄ™dowy wypeÅ‚niony skan",
    "certificate": "zaÅ›wiadczenie o niekaralnoÅ›ci uzupeÅ‚nione",
    "authorization": "upowaÅ¼nienie wypeÅ‚nione dane",
    "other": "pismo urzÄ™dowe wypeÅ‚nione skan"
}

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

def download_images(query, folder_name):
    print(f"\nðŸš€ POBIERANIE WYPEÅNIONYCH: {folder_name.upper()}")
    search_url = f"https://www.bing.com/images/search?q={query.replace(' ', '+')}&form=HDRSC2"
    
    try:
        response = requests.get(search_url, headers=HEADERS, timeout=15)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        target_path = os.path.join(OUTPUT_DIR, folder_name)
        os.makedirs(target_path, exist_ok=True)

        links = []
        for a in soup.find_all("a", {"class": "iusc"}):
            if "m" in a.attrs:
                m = json.loads(a["m"])
                links.append(m["murl"])

        print(f"  ðŸ” Linki: {len(links)}")
        
        downloaded = 0
        for url in links:
            if downloaded >= LIMIT: break
            try:
                if any(ext in url.lower() for ext in [".pdf", ".html", ".php"]): continue
                ext = ".jpg" if ".png" not in url.lower() else ".png"
                
                res = requests.get(url, headers=HEADERS, timeout=7)
                if res.status_code == 200 and "text/html" not in res.headers.get('Content-Type', ''):
                    file_name = f"{folder_name}_{downloaded}{ext}"
                    with open(os.path.join(target_path, file_name), "wb") as f:
                        f.write(res.content)
                    print(f"    âœ… [{downloaded+1}/{LIMIT}] {file_name}")
                    downloaded += 1
                    if downloaded % 5 == 0: time.sleep(1)
            except: continue

    except Exception as e:
        print(f"  ðŸš¨ BÅ‚Ä…d: {e}")

if __name__ == "__main__":
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    for i, (folder, query) in enumerate(CATEGORIES.items()):
        download_images(query, folder)
        wait = random.uniform(3, 6)
        print(f"ðŸ˜´ Przerwa {wait:.1f}s... ({i+1}/{len(CATEGORIES)})")
        time.sleep(wait)